"""
üîá Silence Service - Wrapper para v-services/ffmpeg/detect_silence e silence_cut

Encapsula chamadas para detec√ß√£o e corte de sil√™ncios via v-services.
"""

import os
import logging
import requests
from typing import Dict, List, Optional, Any

logger = logging.getLogger(__name__)

# URL base do v-services (usar ALB interno para bypass Cloudflare)
V_SERVICES_URL = os.environ.get('V_SERVICES_URL', 'https://services.vinicius.ai')
V_SERVICES_HOST = os.environ.get('V_SERVICES_HOST', 'services.vinicius.ai')
V_SERVICES_TOKEN = os.environ.get('V_SERVICES_AUTH_TOKEN', '612d13aee901126f5101611fc5d1a53a348c6407b8653b5428fb9cca5ffe9d21')


class SilenceService:
    """
    Wrapper para os servi√ßos de sil√™ncio do v-services.
    
    Endpoints:
    - /ffmpeg/detect_silence
    - /ffmpeg/silence_cut
    """
    
    def __init__(self, base_url: Optional[str] = None):
        self.base_url = base_url or V_SERVICES_URL
        self.host = V_SERVICES_HOST
        self.detect_endpoint = f"{self.base_url}/ffmpeg/detect_silence"
        self.cut_endpoint = f"{self.base_url}/ffmpeg/silence_cut"
        self.timeout = 600  # 10 minutos
        self.headers = {
            "Content-Type": "application/json",
            "Host": self.host,
            "Authorization": f"Bearer {V_SERVICES_TOKEN}"
        }
    
    def detect_silence(
        self,
        url: str,
        silence_threshold: Optional[float] = None,
        min_silence_duration: float = 0.5,
        detect_speech: bool = True,
        vad_aggressiveness: int = 2,
        silence_offset: float = 0.0,   # üîß v4.1: 0.3‚Üí0.0 (multi-arquivo)
        threshold_offset: float = 3,   # üîß v4.1: 5‚Üí3 (menos agressivo)
        minimum_speech_duration: float = 0.4,  # üîß v4.1: 0.6‚Üí0.4
        trim_start: float = 0.0,       # üîß v4.1: 0.3‚Üí0.0 (multi-arquivo: trim por v√≠deo cortava fala)
        trim_end: float = 0.0,         # üîß v4.1: 0‚Üí0 (expl√≠cito)
        volume_analysis: Optional[Dict[str, Any]] = None  # üÜï v2.8.0: Dados do normalizador
    ) -> Dict[str, Any]:
        """
        Detecta per√≠odos de sil√™ncio em um v√≠deo.
        
        Args:
            url: URL do v√≠deo
            silence_threshold: Threshold em dB (se None, usa volume_analysis ou auto-detect)
            min_silence_duration: Dura√ß√£o m√≠nima do sil√™ncio em segundos
            detect_speech: Usar VAD para detectar fala
            vad_aggressiveness: Agressividade do VAD (1-3)
            silence_offset: Offset em segundos
            threshold_offset: Offset do threshold em dB
            minimum_speech_duration: Dura√ß√£o m√≠nima da fala
            trim_start: Trim no in√≠cio em segundos
            trim_end: Trim no final em segundos
            volume_analysis: üÜï v2.8.0 - Dados de an√°lise de volume do normalizador
                             Se fornecido, usa min_speech_level para calcular threshold
            
        Returns:
            Dict com per√≠odos de sil√™ncio detectados:
            {
                "silence_periods": [
                    {"start": 0.0, "end": 1.5, "duration": 1.5},
                    ...
                ],
                "speech_periods": [
                    {"start": 1.5, "end": 5.0, "duration": 3.5},
                    ...
                ],
                "total_duration": 120.5,
                "total_silence_duration": 25.3,
                "processing_time_seconds": 5.2,
                "threshold_info": {...}  # üÜï v2.8.0: Info de como threshold foi calculado
            }
        """
        payload = {
            "url": url,
            "min_silence_duration": min_silence_duration,
            "detect_speech": detect_speech,
            "vad_aggressiveness": vad_aggressiveness,
            "silence_offset": silence_offset,
            "threshold_offset": threshold_offset,
            "minimum_speech_duration": minimum_speech_duration,
            "trim_start": trim_start,
            "trim_end": trim_end
        }
        
        # Threshold pode ser din√¢mico (calculado do mean_volume ou min_speech_level)
        if silence_threshold is not None:
            payload["silence_threshold"] = silence_threshold
        
        # üÜï v2.8.0: Passar volume_analysis para usar min_speech_level
        if volume_analysis:
            payload["volume_analysis"] = volume_analysis
            min_speech_level = volume_analysis.get('min_speech_level')
            noise_floor = volume_analysis.get('noise_floor')
            suggested_threshold = volume_analysis.get('suggested_silence_threshold')
            logger.info(f"üìä [DETECT_SILENCE] Usando volume_analysis do normalizador:")
            logger.info(f"   üó£Ô∏è min_speech_level: {min_speech_level}dB" if min_speech_level else "   üó£Ô∏è min_speech_level: N/A")
            logger.info(f"   üìâ noise_floor: {noise_floor}dB" if noise_floor else "   üìâ noise_floor: N/A")
            logger.info(f"   üéØ suggested_threshold: {suggested_threshold}dB" if suggested_threshold else "   üéØ suggested_threshold: N/A")
        
        # üÜï v2.7.5: LOG DETALHADO do payload para debug
        logger.info(f"üîç [DETECT_SILENCE] Payload completo:")
        logger.info(f"   üìπ URL: ...{url[-50:] if url else 'None'}")
        logger.info(f"   ‚è±Ô∏è min_silence_duration: {min_silence_duration}s")
        logger.info(f"   üó£Ô∏è minimum_speech_duration: {minimum_speech_duration}s")
        logger.info(f"   üìê silence_offset: {silence_offset}s")
        logger.info(f"   üîä silence_threshold: {silence_threshold or 'AUTO (from volume_analysis or auto-detect)'}")
        logger.info(f"   üìä threshold_offset: {threshold_offset}dB")
        logger.info(f"   ‚úÇÔ∏è trim_start: {trim_start}s, trim_end: {trim_end}s")
        
        try:
            response = requests.post(
                self.detect_endpoint,
                json=payload,
                timeout=self.timeout,
                headers=self.headers
            )
            
            response.raise_for_status()
            result = response.json()
            
            silence_count = len(result.get('silence_periods', []))
            logger.info(f"‚úÖ Detec√ß√£o conclu√≠da: {silence_count} per√≠odos de sil√™ncio")
            return result
            
        except requests.exceptions.Timeout:
            logger.error(f"‚è±Ô∏è Timeout na detec√ß√£o ap√≥s {self.timeout}s")
            return {"error": "Timeout na detec√ß√£o de sil√™ncio", "status": "failed"}
            
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erro na detec√ß√£o: {e}")
            return {"error": str(e), "status": "failed"}
    
    def cut_silence(
        self,
        input_file: str,
        output_file: str,
        clips: List[Dict],
        clips_type: str = "silence_periods",
        cut_mode: str = "all_silences",
        fast_copy: bool = False,         # üîß v4.2: True‚ÜíFalse (cortes precisos, evita perda por keyframe)
        optimize_keyframes: bool = False, # üîß v4.2: True‚ÜíFalse (desnecess√°rio com re-encoding)
        keyframe_precision: str = "medium",
        parallel_processing: bool = True,
        preset: str = "ultrafast",
        quality: int = 22,
        target_fps: int = None  # üÜï Converter para FPS espec√≠fico (ex: 30)
    ) -> Dict[str, Any]:
        """
        Corta sil√™ncios de um v√≠deo baseado nos clips detectados.
        
        Args:
            input_file: URL ou caminho do v√≠deo de entrada
            output_file: Nome do arquivo de sa√≠da (sem extens√£o)
            clips: Lista de per√≠odos (do detect_silence)
            clips_type: "silence_periods" (remove) ou "speech_periods" (mant√©m)
            cut_mode: "all_silences" ou "only_edges"
            fast_copy: Usar stream copy para velocidade
            optimize_keyframes: Otimizar keyframes
            keyframe_precision: "ultra", "high", "medium"
            parallel_processing: Processar em paralelo
            preset: Preset do FFmpeg
            quality: CRF (0=melhor, 51=pior)
            target_fps: üÜï FPS de destino (None = manter original, 30 = converter para 30fps)
            
        Returns:
            Dict com resultado do corte:
            {
                "status": "completed",
                "output_url": "https://...",
                "shared_path": "/app/shared-storage/...",
                "original_duration": 120.5,
                "final_duration": 95.2,
                "removed_duration": 25.3,
                "processing_time_seconds": 45.6
            }
        """
        payload = {
            "input_file": input_file,
            "output_file": output_file,
            "clips": clips,
            "clips_type": clips_type,
            "cut_mode": cut_mode,
            "fast_copy": fast_copy,
            "optimize_keyframes": optimize_keyframes,
            "keyframe_precision": keyframe_precision,
            "parallel_processing": parallel_processing,
            "preset": preset,
            "quality": quality
        }
        
        # üÜï Adicionar target_fps se especificado
        if target_fps:
            payload["target_fps"] = target_fps
            # N√£o usar fast_copy quando converter FPS (precisa re-codificar)
            payload["fast_copy"] = False
            # üîß NVENC n√£o suporta preset "ultrafast", usar "fast" que funciona com ambos
            payload["preset"] = "fast"
            # üîß For√ßar libx264 para evitar problemas de preset com NVENC
            payload["hardware_accel"] = "cpu"
            logger.info(f"   üìê Convertendo para {target_fps} FPS (usando libx264 para compatibilidade)")
        
        logger.info(f"‚úÇÔ∏è Cortando sil√™ncios do v√≠deo (mode: {cut_mode})")
        
        try:
            response = requests.post(
                self.cut_endpoint,
                json=payload,
                timeout=self.timeout,
                headers=self.headers
            )
            
            response.raise_for_status()
            result = response.json()
            
            removed = result.get('removed_duration', 0)
            logger.info(f"‚úÖ Corte conclu√≠do: {removed}s de sil√™ncio removido")
            return result
            
        except requests.exceptions.Timeout:
            logger.error(f"‚è±Ô∏è Timeout no corte ap√≥s {self.timeout}s")
            return {"error": "Timeout no corte de sil√™ncio", "status": "failed"}
            
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erro no corte: {e}")
            return {"error": str(e), "status": "failed"}
    
    def cut_silence_hybrid(
        self,
        input_file: str,
        output_prefix: str,
        clips: List[Dict],
        clips_type: str = "speech_periods",
        fast_copy: bool = False,
        optimize_keyframes: bool = False,
        keyframe_precision: str = "medium",
        preset: str = "ultrafast",
        quality: int = 23,
        min_speech_duration: float = 0.0  # üÜï v2.9.40: Filtro de dura√ß√£o m√≠nima
    ) -> Dict[str, Any]:
        """
        üÜï v2.9.0: HYBRID SILENCE CUT
        
        Corta sil√™ncios gerando:
        1. Clips de v√≠deo SEPARADOS (n√£o concatenados) - para v-editor
        2. √Åudio CONCATENADO √∫nico - para transcri√ß√£o (Whisper/AssemblyAI)
        
        Isso resolve problemas de sync mantendo flexibilidade para o v-editor.
        
        üîß v2.9.50: Defaults alterados para cortes PRECISOS (re-encoding)
        fast_copy=False evita imprecis√£o por keyframe alignment do FFmpeg.
        
        Args:
            input_file: URL ou caminho do v√≠deo de entrada
            output_prefix: Prefixo para nomes dos arquivos
            clips: Lista de per√≠odos (do detect_silence)
            clips_type: "silence_periods" (remove) ou "speech_periods" (mant√©m)
            fast_copy: Usar stream copy (r√°pido mas impreciso nos cortes)
            optimize_keyframes: Otimizar keyframes antes (s√≥ √∫til com fast_copy)
            keyframe_precision: "ultra", "high", "medium"
            preset: Preset do FFmpeg (para re-encoding)
            quality: CRF (0=melhor, 51=pior)
            
        Returns:
            Dict com resultado do corte h√≠brido:
            {
                "status": "completed",
                "audio_concatenated": {
                    "url": "https://...",
                    "shared_path": "ffmpeg/audio/...",
                    "duration_seconds": 95.2
                },
                "video_segments": [
                    {
                        "url": "https://...",
                        "shared_path": "ffmpeg/videos/...",
                        "original_start": 0.5,
                        "original_end": 5.2,
                        "audio_offset": 0.0,
                        "duration": 4.7
                    },
                    ...
                ],
                "total_segments": 15,
                "original_duration": 120.5,
                "final_audio_duration": 95.2,
                "removed_duration": 25.3
            }
        """
        hybrid_endpoint = f"{self.base_url}/ffmpeg/silence_cut_hybrid"
        
        payload = {
            "input_file": input_file,
            "output_prefix": output_prefix,
            "clips": clips,
            "clips_type": clips_type,
            "fast_copy": fast_copy,
            "optimize_keyframes": optimize_keyframes,
            "keyframe_precision": keyframe_precision,
            "preset": preset,
            "quality": quality,
            "min_speech_duration": min_speech_duration  # üÜï v2.9.40
        }
        
        cut_mode_label = "FAST COPY (keyframe)" if fast_copy else "PRECISE (re-encoding)"
        logger.info(f"üîÄ [HYBRID CUT] Cortando sil√™ncios (modo h√≠brido)")
        logger.info(f"   üìä {len(clips)} clips ({clips_type})")
        logger.info(f"   üéØ Modo de corte: {cut_mode_label}")
        logger.info(f"   üó£Ô∏è min_speech_duration: {min_speech_duration}s")
        
        try:
            response = requests.post(
                hybrid_endpoint,
                json=payload,
                timeout=self.timeout,
                headers=self.headers
            )
            
            response.raise_for_status()
            result = response.json()
            
            if result.get("status") == "completed":
                segments_count = result.get('total_segments', 0)
                audio_duration = result.get('audio_concatenated', {}).get('duration_seconds', 0)
                logger.info(f"‚úÖ Corte h√≠brido conclu√≠do: {segments_count} clips, {audio_duration:.2f}s de √°udio")
            
            return result
            
        except requests.exceptions.Timeout:
            logger.error(f"‚è±Ô∏è Timeout no corte h√≠brido ap√≥s {self.timeout}s")
            return {"error": "Timeout no corte h√≠brido de sil√™ncio", "status": "failed"}
            
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erro no corte h√≠brido: {e}")
            return {"error": str(e), "status": "failed"}
    
    def health_check(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel"""
        try:
            response = requests.get(
                f"{self.base_url}/ffmpeg/health",
                timeout=10,
                headers={"Host": self.host}
            )
            return response.status_code == 200
        except:
            return False

