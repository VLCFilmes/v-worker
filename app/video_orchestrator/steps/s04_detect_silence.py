"""
Step 04: Detec√ß√£o de sil√™ncios no v√≠deo.

v4.0: Multi-arquivo ‚Äî detecta sil√™ncio POR V√çDEO com paralelismo.
L√™ configura√ß√µes de state.options (do template).
"""

import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from ._base import *

MAX_CONCURRENT_DETECT = int(os.environ.get('PIPELINE_MAX_CONCURRENT_DETECT', '4'))


@register_step(
    name="detect_silence",
    description="Detecta per√≠odos de sil√™ncio no v√≠deo (multi-arquivo)",
    category="preprocessing",
    depends_on=["normalize"],
    produces=["silence_detection"],
    optional=True,
    estimated_duration_s=15,
    cost_category="cpu",
    retryable=True,
    sse_step_name="SILENCE_CUT",
    tool_schema={
        "description": "Detecta sil√™ncios no v√≠deo para corte",
        "input": {"silence_threshold": "float?", "min_silence_duration": "float?"},
        "output": {"silence_periods": "int", "speech_periods": "int"}
    }
)
def detect_silence_step(state: PipelineState, params: dict) -> PipelineState:
    # ‚îÄ‚îÄ‚îÄ Verificar se silence cut est√° habilitado ‚îÄ‚îÄ‚îÄ
    opts = state.options or {}
    silence_enabled = opts.get('silence_removal', True)
    # Tamb√©m checar 'silence_cut' (nome usado pelo chat_flask)
    if not silence_enabled and not opts.get('silence_cut', False):
        logger.info("‚è≠Ô∏è [DETECT_SILENCE] Silence removal desabilitado nas options")
        return state

    from ..services.silence_service import SilenceService
    service = SilenceService()

    # ‚îÄ‚îÄ‚îÄ Ler configura√ß√µes de state.options (do template) ‚îÄ‚îÄ‚îÄ
    # üîß v4.1: Defaults calibrados (09/Fev/2026) ‚Äî multi-arquivo
    # Ver docs: 04-DETECT-SILENCE/README.md para guia de ajuste
    silence_threshold = opts.get('silence_threshold') or params.get('silence_threshold')
    min_silence_duration = opts.get('min_silence_duration', 0.5)
    silence_offset = opts.get('silence_offset', 0.0)          # v4.1: 0.3‚Üí0.0
    threshold_offset = opts.get('threshold_offset', 3)         # v4.1: 5‚Üí3
    # Template usa 'min_speech_duration', c√≥digo original usava 'minimum_speech_duration'
    minimum_speech_duration = (
        opts.get('min_speech_duration')
        or opts.get('minimum_speech_duration')
        or 0.4                                                  # v4.1: 0.6‚Üí0.4
    )
    trim_start = opts.get('trim_start', 0.0)                   # v4.1: 0.3‚Üí0.0
    trim_end = opts.get('trim_end', 0.0)

    # ‚îÄ‚îÄ‚îÄ Multi-arquivo: detectar sil√™ncio POR V√çDEO ‚îÄ‚îÄ‚îÄ
    videos = state.videos or []
    videos_with_urls = []
    for v in videos:
        url = v.get('retake_cut_url') or v.get('normalized_url') or v.get('url')
        if url:
            videos_with_urls.append((v, url))

    if not videos_with_urls:
        # Fallback single-file (backward compat)
        video_url = state.normalized_video_url or state.get_video_url_for_processing()
        if not video_url:
            logger.warning("‚ö†Ô∏è [DETECT_SILENCE] Sem URL de v√≠deo")
            return state
        videos_with_urls = [({}, video_url)]

    if len(videos_with_urls) == 1:
        # ‚îÄ‚îÄ‚îÄ Single video: comportamento original ‚îÄ‚îÄ‚îÄ
        video_dict, url = videos_with_urls[0]
        result = _detect_for_single_video(
            service, url, silence_threshold, min_silence_duration,
            silence_offset, threshold_offset, minimum_speech_duration,
            trim_start, trim_end, state.normalization_stats,
        )
        if result.get('error'):
            logger.warning(f"‚ö†Ô∏è [DETECT_SILENCE] Falhou: {result['error']}")
            return state

        _log_detection_result(result, url)

        # Enriquecer video dict
        if video_dict:
            video_dict['silence_detection'] = result

        return state.with_updates(
            silence_detection=result,
            videos=[v for v in videos] if videos else state.videos,
        )
    else:
        # ‚îÄ‚îÄ‚îÄ Multi-arquivo: paralelo com ThreadPoolExecutor ‚îÄ‚îÄ‚îÄ
        logger.info(
            f"üîç [DETECT_SILENCE] Multi-arquivo: {len(videos_with_urls)} v√≠deos "
            f"(max_concurrent={MAX_CONCURRENT_DETECT})"
        )

        results_map = {}
        errors = []

        with ThreadPoolExecutor(max_workers=min(MAX_CONCURRENT_DETECT, len(videos_with_urls))) as executor:
            futures = {}
            for video_dict, url in videos_with_urls:
                vid_id = video_dict.get('asset_id') or video_dict.get('upload_id') or url[-20:]
                # v4.1: Usar volume_analysis da normaliza√ß√£o POR V√çDEO
                video_vol_analysis = video_dict.get('normalization_stats') or None
                if video_vol_analysis:
                    logger.info(
                        f"üìä [DETECT_SILENCE] {vid_id[:8]}: usando volume_analysis da normaliza√ß√£o"
                    )
                future = executor.submit(
                    _detect_for_single_video,
                    service, url, silence_threshold, min_silence_duration,
                    silence_offset, threshold_offset, minimum_speech_duration,
                    trim_start, trim_end, video_vol_analysis,
                )
                futures[future] = (vid_id, video_dict, url)

            for future in as_completed(futures):
                vid_id, video_dict, url = futures[future]
                try:
                    result = future.result()
                    if result.get('error'):
                        errors.append(f"{vid_id}: {result['error']}")
                        logger.warning(f"‚ö†Ô∏è [DETECT_SILENCE] {vid_id}: {result['error']}")
                    else:
                        results_map[vid_id] = result
                        video_dict['silence_detection'] = result
                        _log_detection_result(result, url, vid_id)
                except Exception as e:
                    errors.append(f"{vid_id}: {e}")
                    logger.error(f"‚ùå [DETECT_SILENCE] {vid_id}: {e}")

        if not results_map:
            logger.warning(f"‚ö†Ô∏è [DETECT_SILENCE] Nenhuma detec√ß√£o bem-sucedida")
            return state

        # Consolidar: silence_detection cont√©m agregado (para backward compat)
        all_silence = []
        all_speech = []
        for r in results_map.values():
            all_silence.extend(r.get('silence_periods', []))
            all_speech.extend(r.get('speech_periods', []))

        consolidated = {
            'silence_periods': all_silence,
            'speech_periods': all_speech,
            'per_video': results_map,
            'multi_file': True,
            'videos_processed': len(results_map),
            'videos_failed': len(errors),
        }

        logger.info(
            f"‚úÖ [DETECT_SILENCE] Multi-arquivo conclu√≠do: "
            f"{len(results_map)}/{len(videos_with_urls)} v√≠deos OK"
        )

        return state.with_updates(
            silence_detection=consolidated,
            videos=[v for v in videos],
        )


def _detect_for_single_video(
    service, url, silence_threshold, min_silence_duration,
    silence_offset, threshold_offset, minimum_speech_duration,
    trim_start, trim_end, volume_analysis,
):
    """Wrapper para detectar sil√™ncio em um √∫nico v√≠deo."""
    return service.detect_silence(
        url=url,
        silence_threshold=silence_threshold,
        min_silence_duration=min_silence_duration,
        silence_offset=silence_offset,
        threshold_offset=threshold_offset,
        minimum_speech_duration=minimum_speech_duration,
        trim_start=trim_start,
        trim_end=trim_end,
        volume_analysis=volume_analysis,
    )


def _log_detection_result(result, url, vid_id=None):
    """Log resultado de detec√ß√£o."""
    prefix = f"[{vid_id}] " if vid_id else ""
    silence_count = len(result.get('silence_periods', []))
    speech_count = len(result.get('speech_periods', []))
    logger.info(
        f"‚úÖ [DETECT_SILENCE] {prefix}Detectados: "
        f"{silence_count} sil√™ncios, {speech_count} falas"
    )
